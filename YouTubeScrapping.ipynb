{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For loading the webdriver from selenium\n",
    "from selenium import webdriver \n",
    "# Loading the options from selenium for chrome browser\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "# Loading for the keys event in order to scroll and use the keys virtually for the purpose\n",
    "from selenium.webdriver.common.keys import Keys \n",
    "# Loadig from time which has a property sleep for our assignment purpose\n",
    "import time as time\n",
    "# Loading for writing into the CSV\n",
    "import csv\n",
    "# Loading for creating the DataFrame purpose\n",
    "import pandas as pd\n",
    "# Loading for the regular expression for our assignment purpose\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locationOfWebdriver = \"D:/Files/chromedriver_win32/chromedriver.exe\"\n",
    "# We are trying to open in the incognito mode\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--incognito\")\n",
    "driver = webdriver.Chrome(executable_path = locationOfWebdriver, chrome_options = chrome_options)\n",
    "# URL which we are trying to load in the browser\n",
    "driver.get(\"https://www.youtube.com\")\n",
    "# Putting the window in maximum size\n",
    "driver.maximize_window()\n",
    "# Retreiving the serach box id, where in we can pas the text\n",
    "el = driver.find_element_by_xpath(\"//input[@id='search']\")\n",
    "# Addng the text in the box\n",
    "el.send_keys(\"Kishore Kumar\")\n",
    "# this will hit the Enter key virtually and make the event, which will take further action an proceed\n",
    "el.send_keys(Keys.RETURN)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running this loop for 10 links as per the Question, it'll processed accordingly\n",
    "for index in range(1,3,1):\n",
    "    # Initialize an empty dictionary for each reviews commetn\n",
    "    review_dict = {}\n",
    "    \n",
    "    # Putting everything in try catch operation, to control the unexpected behavior occurs \n",
    "    try:\n",
    "        # creating the object pointer which will traverse the path every single time in order to read the content accordingly\n",
    "        youTubeContentPointer = driver.find_elements_by_xpath(\"//*[@id='contents']/ytd-video-renderer[\"+str(index)+\n",
    "                                                \"]//*[@id='video-title']\")\n",
    "        # Now we've got the first link among 10 after Kishore Kumare serach result, where control need to jump further in order to read the comments inside\n",
    "        # At this stage we're reading the href, which is nothing but the first link out of 10 and other respective detials reading it.\n",
    "        # link href, title, subscript channel, number of views and upload time\n",
    "        for content in youTubeContentPointer:\n",
    "            try:\n",
    "                link_url = content.get_attribute('href')                \n",
    "            except:\n",
    "                link_url = \"\"\n",
    "                \n",
    "            try:\n",
    "                link_title = content.get_attribute('title')\n",
    "            except:\n",
    "                link_title = \"\"\n",
    "            \n",
    "            try:\n",
    "                subscription_channel = driver.find_element_by_xpath(\"//*[@id='contents']/ytd-video-renderer[\"+str(index)+\n",
    "                                                    \"]//*[@id='meta']/ytd-video-meta-block//*[@id='byline']\").text\n",
    "            except:\n",
    "                subscription_channel = \"\"\n",
    "            \n",
    "            try:\n",
    "                no_of_views = driver.find_element_by_xpath(\"//*[@id='contents']/ytd-video-renderer[\"+str(index)+\n",
    "                                             \"]//*[@id='meta']/ytd-video-meta-block//*[@id='metadata-line']/span[1]\").text\n",
    "            except:\n",
    "                no_of_views = \"\"\n",
    "                \n",
    "            try:\n",
    "                upload_time = driver.find_element_by_xpath(\"//*[@id='contents']/ytd-video-renderer[\"+str(index)+\n",
    "                                             \"]//*[@id='meta']/ytd-video-meta-block//*[@id='metadata-line']/span[2]\").text\n",
    "            except:\n",
    "                upload_time = \"\"\n",
    "            # Setting this height so that the SORT By field wil appear in the browser window and we can provide the event for the \n",
    "            # Top comments.\n",
    "            height =300\n",
    "            # Jumping inside the first link\n",
    "            driver.get(link_url)\n",
    "            # Putting it for sleep some second\n",
    "            time.sleep(10)\n",
    "            driver.execute_script(\"window.scrollTo(0, \"+str(height)+\")\") \n",
    "            time.sleep(10)\n",
    "            \n",
    "            # Identifying the id for SORT By and then providing the click event\n",
    "            sortby = driver.find_element_by_xpath(\"//*[@id='icon-label']\")\n",
    "            sortby.click()\n",
    "            # Identifying the Top comment string and providing the click event\n",
    "            topcomment = driver.find_element_by_xpath(\"//*[@id='menu']/a[1]/paper-item/paper-item-body/div[1]\")\n",
    "            topcomment.click()\n",
    "            time.sleep(5)\n",
    "            \n",
    "            # now since we've retreive the top comment, will proceed to jump to the end of the screen, so that it loadsup the comment\n",
    "            # on fly and we'll able to retrieve from the desired path.\n",
    "            driver.find_element_by_xpath(\"//*[@id='meta']//*[@id='owner-name']/a\").send_keys(Keys.CONTROL+Keys.END)\n",
    "            \n",
    "            # now will begin to read the 50 comments from each and every link\n",
    "            for commentIndex in range(1,5,1):\n",
    "#                 Declaring the empty string \n",
    "                decide = ''                \n",
    "                # Keeping code to make sure out iteration doesn't halp up after 20 comment, this is required because in each frame\n",
    "                # it loads up only 20 comment, since we need to read 50 commetn, we need to make sure that it does the scroll down\n",
    "                if commentIndex == 19 or commentIndex == 40 or commentIndex == 51:\n",
    "                    height = height + 400\n",
    "                    driver.execute_script(\"window.scrollTo(0, \"+str(height)+\")\")\n",
    "                    driver.find_element_by_xpath(\"//*[@id='meta']//*[@id='owner-name']/a\").send_keys(Keys.CONTROL+Keys.END)\n",
    "                    time.sleep(10)                    \n",
    "                    \n",
    "                # this is tweak, to control whether we've got the replies in the respective comment or not.\n",
    "                replydecision = driver.find_element_by_xpath(\"//*[@id='contents']/ytd-comment-thread-renderer[\"+str(commentIndex)+\n",
    "                                                  \"]//*[@id='replies']\").text\n",
    "                # Three use cases we've\n",
    "#                 1. It can have more than 1 reply\n",
    "#                 2. It wont have any reply in the comment\n",
    "#                 3  It can have only and only one comment\n",
    "#                 Based on all above, will decide what could be the ID of the XPATH\n",
    "                if 'repl' in replydecision:\n",
    "                    decide = 'more'\n",
    "                else:\n",
    "                    decide = 'less'\n",
    "                # Here on just reading the comment and repective vlaue in it.\n",
    "\n",
    "                try:\n",
    "                    user_comment=driver.find_element_by_xpath(\"//*[@id='contents']/ytd-comment-thread-renderer[\"+str(commentIndex)+\n",
    "                                                         \"]//*[@id='content-text']\").text\n",
    "                except:\n",
    "                    user_comment= \"\"\n",
    "                try:\n",
    "                    user_like = driver.find_element_by_xpath(\"//*[@id='contents']/ytd-comment-thread-renderer[\"+str(commentIndex)+\n",
    "                                                         \"]//*[@id='vote-count-middle']\").text\n",
    "                except:\n",
    "                    user_like = \"\"\n",
    "                try:\n",
    "                    user_down_vote = driver.find_element_by_xpath(\"//*[@id=\"contents\"]/ytd-comment-thread-renderer[\"+str(commentIndex)+\n",
    "                                      \"]//*[@id='toolbar']//*[@id='reply-button-end']//*[@id='button']//*[@id='text']\").text\n",
    "                except:\n",
    "                    user_down_vote = \"\"\n",
    "                    \n",
    "                try:\n",
    "                    published = driver.find_element_by_xpath(\"//*[@id='contents']/ytd-comment-thread-renderer[\"+str(commentIndex)+\n",
    "                                                         \"]//*[@id='published-time-text']\").text\n",
    "                except:\n",
    "                    published = \"\"\n",
    "                try:\n",
    "                    user_author = driver.find_element_by_xpath(\"//*[@id='contents']/ytd-comment-thread-renderer[\"+str(commentIndex)+\n",
    "                                                         \"]//*[@id='author-text']\").text\n",
    "                except:\n",
    "                    user_author = \"\"\n",
    "                    \n",
    "                if 'more' in decide:\n",
    "                    user_replies = driver.find_element_by_xpath(\"//*[@id='contents']/ytd-comment-thread-renderer[\"+str(commentIndex)+\n",
    "                                                         \"]//*[@id='\"+str(decide)+\"']/div/paper-button\").text   \n",
    "                    if 'reply' in user_replies:\n",
    "                        user_replies = 1\n",
    "                    else:\n",
    "                        user_replies = re.findall(\"\\d+\", user_replies)\n",
    "                        user_replies =max(map(int,user_replies))\n",
    "                else:\n",
    "                    user_replies = \"NA\"\n",
    "                print(user_replies)        \n",
    "                \n",
    "                # Writing the cotent in the dictionary and later stage we can dump the same in CSV\n",
    "                review_dict['link_url'] = link_url\n",
    "                review_dict['link_title'] = link_title\n",
    "                review_dict['subscription_channel'] = subscription_channel\n",
    "                review_dict['no_of_views'] = no_of_views\n",
    "                review_dict['upload_time'] = upload_time\n",
    "                review_dict['user_author'] = user_author\n",
    "                review_dict['published'] = published\n",
    "                review_dict['user_like'] = user_like\n",
    "                review_dict['user_comment'] = user_comment\n",
    "                review_dict['user_replies'] = user_replies\n",
    "                writer.writerow(review_dict.values())\n",
    "                print(\"Processing - \"+str(commentIndex))\n",
    "            # Putting this because we need to go back to the previous screen, so that we can pick the second link and moveon\n",
    "            driver.execute_script(\"window.history.go(-1)\")\n",
    "        print('Processed  the link ' + str(index)) \n",
    "\n",
    "    \n",
    "    except Exception as e:\n",
    "                print(e)\n",
    "                csv_file.close()\n",
    "                driver.close()\n",
    "                break\n",
    "\n",
    "# Shutting down the csv and driver at closed state.\n",
    "csv_file.close()\n",
    "driver.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second question\n",
    "# Loading the API client to make the call\n",
    "from newsapi import NewsApiClient\n",
    "# Loading the Pandas to Dataframe purpose\n",
    "import pandas as pd\n",
    "\n",
    "# Initializing the empty list whcih is of data\n",
    "data = []\n",
    "# Reason of putting untill 50, because it wont throught the eror, otherwise it will show that we need to login as paid member \n",
    "# in order to get more content\n",
    "for index in range (1,51,1):\n",
    "    # Please make sure to use the API Key which is yours\n",
    "    newsapi = NewsApiClient(api_key='588dfcb77ab14a3fa6fa6ec29978f0d4')\n",
    "    all_articles = newsapi.get_everything(q='business analytics',\n",
    "                                      language='en',\n",
    "                                      sort_by='relevancy',\n",
    "                                      page=index)\n",
    "    # At one shot we only get the 20 articles, so looping through the all the way so that we can read teh respective values out of it\n",
    "    for inner in range (1,20,1):\n",
    "        \n",
    "        author = all_articles['articles'][inner]['author']\n",
    "        title = all_articles['articles'][inner]['title']\n",
    "        description = all_articles['articles'][inner]['description']\n",
    "        publishedAt = all_articles['articles'][inner]['publishedAt']\n",
    "        content = all_articles['articles'][inner]['content']\n",
    "        source_id = all_articles['articles'][inner]['source']['id']\n",
    "        source_name = all_articles['articles'][inner]['source']['name']\n",
    "        # Keep on appending the same in the variable\n",
    "        data.append((author,title,description,publishedAt,content,source_id,source_name))\n",
    "        # Creating the dataframe\n",
    "        df = pd.DataFrame(data,columns=['Author','Title','Description','PublishedAt','Content','Source_Id','Source_Name'])\n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
